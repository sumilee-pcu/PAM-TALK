#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PAM-TALK ìµœì í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ê¸°ì¡´ ì„œë²„ vs ìµœì í™” ì„œë²„ ì„±ëŠ¥ ë¹„êµ
"""

import requests
import time
import threading
import statistics
import json
from datetime import datetime


class OptimizedTester:
    """ìµœì í™” ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    def __init__(self, base_url="http://localhost:5001"):
        self.base_url = base_url
        self.results = []

    def test_single_request(self, endpoint, timeout=10):
        """ë‹¨ì¼ ìš”ì²­ ì„±ëŠ¥ ì¸¡ì •"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()

        try:
            response = requests.get(url, timeout=timeout)
            end_time = time.time()
            return {
                'endpoint': endpoint,
                'response_time': end_time - start_time,
                'status_code': response.status_code,
                'success': 200 <= response.status_code < 400,
                'cached': 'cached' in response.text.lower()
            }
        except Exception as e:
            return {
                'endpoint': endpoint,
                'response_time': time.time() - start_time,
                'status_code': 0,
                'success': False,
                'error': str(e)
            }

    def concurrent_test(self, endpoint, num_requests):
        """ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸"""
        results = []
        threads = []

        def worker():
            result = self.test_single_request(endpoint)
            results.append(result)

        start_time = time.time()

        for _ in range(num_requests):
            thread = threading.Thread(target=worker)
            threads.append(thread)
            thread.start()

        for thread in threads:
            thread.join()

        end_time = time.time()

        return results, end_time - start_time

    def cache_test(self):
        """ìºì‹± íš¨ê³¼ í…ŒìŠ¤íŠ¸"""
        print("  ìºì‹œ íš¨ê³¼ í…ŒìŠ¤íŠ¸:")

        # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
        result1 = self.test_single_request("/api/farms")
        print(f"    ì²« ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤): {result1['response_time']:.3f}s")

        # ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ íˆíŠ¸)
        result2 = self.test_single_request("/api/farms")
        print(f"    ë‘˜ì§¸ ìš”ì²­ (ìºì‹œ íˆíŠ¸): {result2['response_time']:.3f}s")

        improvement = (result1['response_time'] - result2['response_time']) / result1['response_time'] * 100
        print(f"    ìºì‹œ ê°œì„ ìœ¨: {improvement:.1f}%")

        return result1, result2

    def run_optimized_test(self):
        """ìµœì í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("PAM-TALK ìµœì í™” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("=" * 40)

        # ê¸°ë³¸ ì—°ê²° í™•ì¸
        try:
            response = requests.get(f"{self.base_url}/api/health", timeout=5)
            if response.status_code != 200:
                print("ERROR: ìµœì í™” ì„œë²„ ì—°ê²° ì‹¤íŒ¨")
                return None
            print("ìµœì í™” ì„œë²„ ì—°ê²° OK")
            print(f"ì„œë²„ ë²„ì „: {response.json().get('version', 'Unknown')}")
            print(f"ìºì‹œ ìƒíƒœ: {response.json().get('cache_status', 'Unknown')}")
        except Exception as e:
            print(f"ERROR: {e}")
            return None

        # 1. ë‹¨ì¼ ìš”ì²­ í…ŒìŠ¤íŠ¸
        print(f"\n1. ë‹¨ì¼ ìš”ì²­ ì„±ëŠ¥")
        endpoints = ["/api/health", "/api/farms", "/api/transactions", "/api/dashboard"]
        single_results = []

        for endpoint in endpoints:
            result = self.test_single_request(endpoint)
            single_results.append(result)
            status = "OK" if result['success'] else "FAIL"
            cached = " [CACHED]" if result.get('cached', False) else ""
            print(f"   {endpoint}: {result['response_time']:.3f}s [{status}]{cached}")

        # 2. ìºì‹œ íš¨ê³¼ í…ŒìŠ¤íŠ¸
        print(f"\n2. ìºì‹± ì‹œìŠ¤í…œ íš¨ê³¼")
        cache_result1, cache_result2 = self.cache_test()

        # 3. ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸
        print(f"\n3. ë™ì‹œ ìš”ì²­ ì„±ëŠ¥")
        concurrent_levels = [10, 20, 50, 100]

        best_rps = 0
        for level in concurrent_levels:
            results, total_time = self.concurrent_test("/api/health", level)
            successful = [r for r in results if r['success']]

            if successful:
                avg_response = statistics.mean([r['response_time'] for r in successful])
                success_rate = len(successful) / len(results) * 100
                rps = len(results) / total_time if total_time > 0 else 0

                print(f"   {level}ê°œ ë™ì‹œìš”ì²­:")
                print(f"     í‰ê· ì‘ë‹µ: {avg_response:.3f}s")
                print(f"     ì„±ê³µë¥ : {success_rate:.1f}%")
                print(f"     RPS: {rps:.1f}")

                if success_rate > 95:  # 95% ì´ìƒ ì„±ê³µì‹œì—ë§Œ ê¸°ë¡
                    best_rps = max(best_rps, rps)

        # 4. ì§€ì† ë¶€í•˜ í…ŒìŠ¤íŠ¸
        print(f"\n4. ì§€ì† ë¶€í•˜ í…ŒìŠ¤íŠ¸ (30ì´ˆ)")
        duration = 30
        end_time = time.time() + duration
        sustained_results = []

        while time.time() < end_time:
            result = self.test_single_request("/api/health")
            sustained_results.append(result)
            time.sleep(0.1)  # 0.1ì´ˆ ê°„ê²©ìœ¼ë¡œ ì¦ê°€

        successful_sustained = [r for r in sustained_results if r['success']]

        if successful_sustained:
            avg_sustained = statistics.mean([r['response_time'] for r in successful_sustained])
            sustained_success_rate = len(successful_sustained) / len(sustained_results) * 100
            sustained_rps = len(sustained_results) / duration

            print(f"   ì´ ìš”ì²­: {len(sustained_results)}ê°œ")
            print(f"   í‰ê· ì‘ë‹µ: {avg_sustained:.3f}s")
            print(f"   ì„±ê³µë¥ : {sustained_success_rate:.1f}%")
            print(f"   ì§€ì† RPS: {sustained_rps:.1f}")

        # 5. ì„±ëŠ¥ í‰ê°€
        print(f"\nìµœì í™” ì„±ëŠ¥ í‰ê°€:")

        single_avg = statistics.mean([r['response_time'] for r in single_results if r['success']])
        print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {single_avg:.3f}s")
        print(f"  ìµœëŒ€ ë™ì‹œ RPS: {best_rps:.1f}")
        print(f"  ì§€ì† í‰ê·  RPS: {sustained_rps:.1f}")

        # Phase 1 ëª©í‘œ ë‹¬ì„±ë„
        target_rps = 50
        achievement = (sustained_rps / target_rps) * 100
        print(f"  Phase 1 ëª©í‘œ ë‹¬ì„±: {achievement:.1f}% ({sustained_rps:.1f}/{target_rps} RPS)")

        if achievement >= 80:
            print("  ìƒíƒœ: ëª©í‘œ ë‹¬ì„± (Phase 1 ì™„ë£Œ)")
        elif achievement >= 50:
            print("  ìƒíƒœ: ëª©í‘œ ê·¼ì ‘ (ì¶”ê°€ ìµœì í™” ê¶Œì¥)")
        else:
            print("  ìƒíƒœ: ì¶”ê°€ ìµœì í™” í•„ìš”")

        # ê²°ê³¼ ë°˜í™˜
        return {
            'single_avg_response': single_avg,
            'best_concurrent_rps': best_rps,
            'sustained_rps': sustained_rps,
            'sustained_success_rate': sustained_success_rate,
            'achievement_percent': achievement,
            'cache_improvement': (cache_result1['response_time'] - cache_result2['response_time']) / cache_result1['response_time'] * 100
        }


def compare_with_baseline():
    """ê¸°ì¡´ ê¸°ì¤€ì ê³¼ ë¹„êµ"""
    print("\n" + "=" * 50)
    print("ê¸°ì¤€ì  vs ìµœì í™” ì„±ëŠ¥ ë¹„êµ")
    print("=" * 50)

    # ê¸°ì¤€ì  ë°ì´í„° ë¡œë“œ
    try:
        with open('simple_baseline_results.json', 'r') as f:
            baseline = json.load(f)
    except FileNotFoundError:
        print("ê¸°ì¤€ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € baseline í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # ìµœì í™” í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = OptimizedTester()
    optimized = tester.run_optimized_test()

    if not optimized:
        return

    print(f"\nì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
    print(f"{'í•­ëª©':<15} {'ê¸°ì¡´':<10} {'ìµœì í™”':<10} {'ê°œì„ ë„':<10}")
    print("-" * 50)

    # RPS ë¹„êµ
    baseline_rps = baseline.get('sustained_rps', 0)
    optimized_rps = optimized['sustained_rps']
    rps_improvement = (optimized_rps - baseline_rps) / baseline_rps * 100 if baseline_rps > 0 else float('inf')
    print(f"{'RPS':<15} {baseline_rps:<10.1f} {optimized_rps:<10.1f} {rps_improvement:<9.1f}%")

    # ì‘ë‹µì‹œê°„ ë¹„êµ
    baseline_response = baseline.get('single_request_avg', 0)
    optimized_response = optimized['single_avg_response']
    response_improvement = (baseline_response - optimized_response) / baseline_response * 100 if baseline_response > 0 else 0
    print(f"{'ì‘ë‹µì‹œê°„(s)':<15} {baseline_response:<10.3f} {optimized_response:<10.3f} {response_improvement:<9.1f}%")

    # ëª©í‘œ ë‹¬ì„±ë„ ë¹„êµ
    baseline_achievement = baseline.get('achievement_percent', 0)
    optimized_achievement = optimized['achievement_percent']
    print(f"{'ëª©í‘œë‹¬ì„±%':<15} {baseline_achievement:<10.1f} {optimized_achievement:<10.1f} +{optimized_achievement-baseline_achievement:<8.1f}%")

    # ì „ì²´ í‰ê°€
    print(f"\nì¢…í•© í‰ê°€:")
    if optimized_rps > baseline_rps * 5:
        print("  ğŸŸ¢ ìš°ìˆ˜í•œ ì„±ëŠ¥ ê°œì„  (5ë°° ì´ìƒ)")
    elif optimized_rps > baseline_rps * 2:
        print("  ğŸŸ¡ ì–‘í˜¸í•œ ì„±ëŠ¥ ê°œì„  (2-5ë°°)")
    elif optimized_rps > baseline_rps:
        print("  ğŸŸ  ë³´í†µ ì„±ëŠ¥ ê°œì„  (í–¥ìƒë¨)")
    else:
        print("  ğŸ”´ ì„±ëŠ¥ ê°œì„  íš¨ê³¼ ì—†ìŒ")

    # ê²°ê³¼ ì €ì¥
    comparison_data = {
        'timestamp': datetime.now().isoformat(),
        'baseline': baseline,
        'optimized': optimized,
        'improvements': {
            'rps_improvement_percent': rps_improvement,
            'response_improvement_percent': response_improvement,
            'achievement_improvement': optimized_achievement - baseline_achievement
        }
    }

    with open('optimization_comparison.json', 'w') as f:
        json.dump(comparison_data, f, indent=2)

    print(f"\në¹„êµ ê²°ê³¼ê°€ 'optimization_comparison.json'ì— ì €ì¥ë¨")


if __name__ == "__main__":
    compare_with_baseline()